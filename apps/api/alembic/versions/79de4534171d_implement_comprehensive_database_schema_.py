"""Implement comprehensive database schema with all models

Revision ID: 79de4534171d
Revises: 001
Create Date: 2025-08-20 13:45:01.604658

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '79de4534171d'
down_revision: Union[str, None] = '001'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # Enable pgvector extension
    op.execute('CREATE EXTENSION IF NOT EXISTS vector')
    
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('billing_transactions',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('type', sa.Enum('CREDIT_PURCHASE', 'SUBSCRIPTION', 'REFUND', name='billingtransactiontype'), nullable=False),
    sa.Column('amount', sa.DECIMAL(precision=10, scale=2), nullable=False),
    sa.Column('currency', sa.String(length=3), nullable=False),
    sa.Column('credits_granted', sa.Integer(), nullable=False),
    sa.Column('payment_provider', sa.String(length=50), nullable=False),
    sa.Column('payment_id', sa.String(length=255), nullable=False),
    sa.Column('status', sa.Enum('PENDING', 'COMPLETED', 'FAILED', 'REFUNDED', name='billingtransactionstatus'), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.CheckConstraint('amount >= 0', name='positive_amount'),
    sa.CheckConstraint('credits_granted >= 0', name='positive_credits_granted'),
    sa.CheckConstraint('length(currency) = 3', name='valid_currency_code'),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('product_matches',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), nullable=False),
    sa.Column('job_id', sa.UUID(), nullable=False),
    sa.Column('product_description', sa.Text(), nullable=False),
    sa.Column('quantity', sa.DECIMAL(precision=10, scale=3), nullable=False),
    sa.Column('unit_of_measure', sa.String(length=50), nullable=False),
    sa.Column('value', sa.DECIMAL(precision=12, scale=2), nullable=False),
    sa.Column('origin_country', sa.String(length=3), nullable=False),
    sa.Column('matched_hs_code', sa.String(length=10), nullable=False),
    sa.Column('confidence_score', sa.DECIMAL(precision=3, scale=2), nullable=False),
    sa.Column('alternative_hs_codes', sa.ARRAY(sa.String()), nullable=True),
    sa.Column('requires_manual_review', sa.Boolean(), nullable=False),
    sa.Column('user_confirmed', sa.Boolean(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.CheckConstraint('confidence_score >= 0 AND confidence_score <= 1', name='valid_confidence_score'),
    sa.CheckConstraint('length(origin_country) = 3', name='valid_origin_country'),
    sa.CheckConstraint('quantity > 0', name='positive_quantity'),
    sa.CheckConstraint('value >= 0', name='positive_value'),
    sa.ForeignKeyConstraint(['job_id'], ['processing_jobs.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.add_column('hs_codes', sa.Column('chapter', sa.String(length=2), nullable=False))
    op.add_column('hs_codes', sa.Column('section', sa.String(length=2), nullable=False))
    op.add_column('hs_codes', sa.Column('embedding', pgvector.sqlalchemy.vector.VECTOR(dim=1536), nullable=True))
    op.add_column('hs_codes', sa.Column('country', sa.String(length=3), nullable=False))
    op.add_column('hs_codes', sa.Column('is_active', sa.Boolean(), nullable=False))
    op.alter_column('hs_codes', 'code',
               existing_type=sa.VARCHAR(length=20),
               type_=sa.String(length=10),
               existing_nullable=False)
    op.alter_column('hs_codes', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False)
    op.drop_index(op.f('ix_hs_codes_code'), table_name='hs_codes')
    op.drop_index(op.f('ix_hs_codes_id'), table_name='hs_codes')
    op.drop_column('hs_codes', 'embedding_vector')
    op.drop_column('hs_codes', 'category')
    op.drop_column('hs_codes', 'is_restricted')
    op.drop_column('hs_codes', 'id')
    op.drop_column('hs_codes', 'tariff_rate')
    op.drop_column('hs_codes', 'created_at')
    op.drop_column('hs_codes', 'units')
    op.add_column('processing_jobs', sa.Column('input_file_name', sa.String(length=255), nullable=False))
    op.add_column('processing_jobs', sa.Column('input_file_url', sa.Text(), nullable=False))
    op.add_column('processing_jobs', sa.Column('input_file_size', sa.BIGINT(), nullable=False))
    op.add_column('processing_jobs', sa.Column('output_xml_url', sa.Text(), nullable=True))
    op.add_column('processing_jobs', sa.Column('credits_used', sa.Integer(), nullable=False))
    op.add_column('processing_jobs', sa.Column('processing_time_ms', sa.Integer(), nullable=True))
    op.add_column('processing_jobs', sa.Column('total_products', sa.Integer(), nullable=False))
    op.add_column('processing_jobs', sa.Column('successful_matches', sa.Integer(), nullable=False))
    op.add_column('processing_jobs', sa.Column('average_confidence', sa.DECIMAL(precision=3, scale=2), nullable=True))
    op.add_column('processing_jobs', sa.Column('country_schema', sa.String(length=3), nullable=False))
    op.add_column('processing_jobs', sa.Column('started_at', sa.DateTime(timezone=True), nullable=True))
    op.alter_column('processing_jobs', 'id',
               existing_type=sa.INTEGER(),
               type_=sa.UUID(),
               existing_nullable=False)
    op.alter_column('processing_jobs', 'user_id',
               existing_type=sa.INTEGER(),
               type_=sa.UUID(),
               existing_nullable=False)
    op.alter_column('processing_jobs', 'error_message',
               existing_type=sa.VARCHAR(),
               type_=sa.Text(),
               existing_nullable=True)
    op.alter_column('processing_jobs', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False)
    op.alter_column('processing_jobs', 'completed_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.drop_index(op.f('ix_processing_jobs_id'), table_name='processing_jobs')
    op.drop_constraint(op.f('processing_jobs_user_id_fkey'), 'processing_jobs', type_='foreignkey')
    op.create_foreign_key(None, 'processing_jobs', 'users', ['user_id'], ['id'], ondelete='CASCADE')
    op.drop_column('processing_jobs', 'updated_at')
    op.drop_column('processing_jobs', 'original_filename')
    op.drop_column('processing_jobs', 'progress')
    op.drop_column('processing_jobs', 'hs_code_matches')
    op.drop_column('processing_jobs', 'xml_output')
    op.drop_column('processing_jobs', 'filename')
    op.drop_column('processing_jobs', 'file_path')
    op.drop_column('processing_jobs', 'extracted_data')
    op.drop_column('processing_jobs', 'file_size')
    op.add_column('users', sa.Column('subscription_tier', sa.Enum('FREE', 'BASIC', 'PREMIUM', 'ENTERPRISE', name='subscriptiontier'), nullable=False))
    op.add_column('users', sa.Column('credits_remaining', sa.Integer(), nullable=False))
    op.add_column('users', sa.Column('credits_used_this_month', sa.Integer(), nullable=False))
    op.add_column('users', sa.Column('company', sa.String(length=255), nullable=True))
    op.add_column('users', sa.Column('country', sa.String(length=3), nullable=False))
    op.add_column('users', sa.Column('last_login_at', sa.DateTime(timezone=True), nullable=True))
    op.alter_column('users', 'id',
               existing_type=sa.INTEGER(),
               type_=sa.UUID(),
               existing_nullable=False,
               existing_server_default=sa.text("nextval('users_id_seq'::regclass)"))
    op.alter_column('users', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False)
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.drop_index(op.f('ix_users_id'), table_name='users')
    op.create_unique_constraint(None, 'users', ['email'])
    op.drop_column('users', 'updated_at')
    op.drop_column('users', 'credits')
    op.drop_column('users', 'name')
    
    # Add optimized indexes for performance
    op.create_index('idx_users_email', 'users', ['email'])
    op.create_index('idx_users_country', 'users', ['country'])
    op.create_index('idx_users_subscription_tier', 'users', ['subscription_tier'])
    op.create_index('idx_users_created_at', 'users', ['created_at'])
    op.create_index('idx_hs_codes_country_active', 'hs_codes', ['country', 'is_active'], 
                    postgresql_where=sa.text('is_active = true'))
    op.create_index('idx_processing_jobs_user_created', 'processing_jobs', ['user_id', 'created_at'], 
                    postgresql_order_by=['user_id', sa.text('created_at DESC')])
    op.create_index('idx_processing_jobs_status', 'processing_jobs', ['status'])
    op.create_index('idx_processing_jobs_country', 'processing_jobs', ['country_schema'])
    
    # Add HNSW vector indexes for similarity search
    op.execute('CREATE INDEX IF NOT EXISTS idx_hs_codes_embedding_cosine ON hs_codes USING hnsw (embedding vector_cosine_ops)')
    op.execute('CREATE INDEX IF NOT EXISTS idx_hs_codes_embedding_l2 ON hs_codes USING hnsw (embedding vector_l2_ops)')
    
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('users', sa.Column('name', sa.VARCHAR(), autoincrement=False, nullable=False))
    op.add_column('users', sa.Column('credits', sa.INTEGER(), autoincrement=False, nullable=False))
    op.add_column('users', sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False))
    op.drop_constraint(None, 'users', type_='unique')
    op.create_index(op.f('ix_users_id'), 'users', ['id'], unique=False)
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
    op.alter_column('users', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False)
    op.alter_column('users', 'id',
               existing_type=sa.UUID(),
               type_=sa.INTEGER(),
               existing_nullable=False,
               existing_server_default=sa.text("nextval('users_id_seq'::regclass)"))
    op.drop_column('users', 'last_login_at')
    op.drop_column('users', 'country')
    op.drop_column('users', 'company')
    op.drop_column('users', 'credits_used_this_month')
    op.drop_column('users', 'credits_remaining')
    op.drop_column('users', 'subscription_tier')
    op.add_column('processing_jobs', sa.Column('file_size', sa.INTEGER(), autoincrement=False, nullable=False))
    op.add_column('processing_jobs', sa.Column('extracted_data', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('processing_jobs', sa.Column('file_path', sa.VARCHAR(), autoincrement=False, nullable=False))
    op.add_column('processing_jobs', sa.Column('filename', sa.VARCHAR(), autoincrement=False, nullable=False))
    op.add_column('processing_jobs', sa.Column('xml_output', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('processing_jobs', sa.Column('hs_code_matches', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('processing_jobs', sa.Column('progress', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False))
    op.add_column('processing_jobs', sa.Column('original_filename', sa.VARCHAR(), autoincrement=False, nullable=False))
    op.add_column('processing_jobs', sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False))
    op.drop_constraint(None, 'processing_jobs', type_='foreignkey')
    op.create_foreign_key(op.f('processing_jobs_user_id_fkey'), 'processing_jobs', 'users', ['user_id'], ['id'])
    op.create_index(op.f('ix_processing_jobs_id'), 'processing_jobs', ['id'], unique=False)
    op.alter_column('processing_jobs', 'completed_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('processing_jobs', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False)
    op.alter_column('processing_jobs', 'error_message',
               existing_type=sa.Text(),
               type_=sa.VARCHAR(),
               existing_nullable=True)
    op.alter_column('processing_jobs', 'user_id',
               existing_type=sa.UUID(),
               type_=sa.INTEGER(),
               existing_nullable=False)
    op.alter_column('processing_jobs', 'id',
               existing_type=sa.UUID(),
               type_=sa.INTEGER(),
               existing_nullable=False)
    op.drop_column('processing_jobs', 'started_at')
    op.drop_column('processing_jobs', 'country_schema')
    op.drop_column('processing_jobs', 'average_confidence')
    op.drop_column('processing_jobs', 'successful_matches')
    op.drop_column('processing_jobs', 'total_products')
    op.drop_column('processing_jobs', 'processing_time_ms')
    op.drop_column('processing_jobs', 'credits_used')
    op.drop_column('processing_jobs', 'output_xml_url')
    op.drop_column('processing_jobs', 'input_file_size')
    op.drop_column('processing_jobs', 'input_file_url')
    op.drop_column('processing_jobs', 'input_file_name')
    op.add_column('hs_codes', sa.Column('units', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('hs_codes', sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False))
    op.add_column('hs_codes', sa.Column('tariff_rate', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('hs_codes', sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False))
    op.add_column('hs_codes', sa.Column('is_restricted', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('hs_codes', sa.Column('category', sa.VARCHAR(), autoincrement=False, nullable=False))
    op.add_column('hs_codes', sa.Column('embedding_vector', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.create_index(op.f('ix_hs_codes_id'), 'hs_codes', ['id'], unique=False)
    op.create_index(op.f('ix_hs_codes_code'), 'hs_codes', ['code'], unique=True)
    op.alter_column('hs_codes', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False)
    op.alter_column('hs_codes', 'code',
               existing_type=sa.String(length=10),
               type_=sa.VARCHAR(length=20),
               existing_nullable=False)
    op.drop_column('hs_codes', 'is_active')
    op.drop_column('hs_codes', 'country')
    op.drop_column('hs_codes', 'embedding')
    op.drop_column('hs_codes', 'section')
    op.drop_column('hs_codes', 'chapter')
    op.drop_table('product_matches')
    op.drop_table('billing_transactions')
    # ### end Alembic commands ###