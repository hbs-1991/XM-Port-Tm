# Story 2.2: HS Code Database Integration

## Status
Draft

## Story
**As a** customs broker,
**I want** the system to have a comprehensive HS code database with AI-powered search capabilities,
**so that** my uploaded products can be accurately matched to the correct HS codes with high confidence scores.

## Acceptance Criteria
1. Implement HS code database with support for country-specific variations (initially Turkmenistan)
2. Store HS codes with descriptions, chapters, sections, and hierarchical relationships
3. Generate and store OpenAI embeddings for each HS code description for similarity search
4. Implement vector similarity search using pgvector for efficient HS code lookup
5. Create data ingestion service to populate/update HS codes from authoritative sources
6. Support bulk operations for initial database seeding (minimum 5,000 codes)
7. Implement caching layer for frequently accessed HS codes using Redis
8. Create API endpoints for HS code search, retrieval, and management
9. Track HS code usage statistics for analytics and optimization
10. Implement database indexing and optimization for sub-100ms query performance

## Tasks / Subtasks

- [ ] Task 1: Set up database schema and pgvector extension (AC: 1, 2, 4)
  - [ ] Create hs_codes table with required fields
  - [ ] Install and configure pgvector extension
  - [ ] Set up vector indexes for similarity search (HNSW)
  - [ ] Create database migrations using Alembic
  - [ ] Add foreign key relationships to product_matches table

- [ ] Task 2: Implement HS code model and repository (AC: 2, 9)
  - [ ] Create HSCode SQLAlchemy model in `/apps/api/src/models/hs_code.py`
  - [ ] Implement HSCodeRepository in `/apps/api/src/repositories/hs_code_repository.py`
  - [ ] Add CRUD operations (create, read, update, delete, bulk operations)
  - [ ] Implement usage tracking methods
  - [ ] Create Pydantic schemas for HS code data validation

- [ ] Task 3: Build OpenAI embedding generation service (AC: 3)
  - [ ] Create embedding service in `/apps/api/src/services/embedding_service.py`
  - [ ] Integrate OpenAI Agents SDK for embedding generation
  - [ ] Implement batch embedding generation for efficiency
  - [ ] Add retry logic and error handling for API failures
  - [ ] Create embedding update mechanism for modified HS codes

- [ ] Task 4: Implement vector similarity search service (AC: 4, 10)
  - [ ] Create search service in `/apps/api/src/services/hs_search_service.py`
  - [ ] Implement cosine similarity search using pgvector
  - [ ] Add configurable similarity threshold (default 0.7)
  - [ ] Implement result ranking and confidence scoring
  - [ ] Add query optimization for sub-100ms performance

- [ ] Task 5: Create data ingestion service (AC: 5, 6)
  - [ ] Build ingestion service in `/apps/api/src/services/hs_ingestion_service.py`
  - [ ] Implement CSV/JSON parser for HS code data
  - [ ] Add validation for required fields and data formats
  - [ ] Create bulk insert with transaction support
  - [ ] Implement progress tracking for large imports
  - [ ] Create seed data script in `/scripts/seed-hs-codes.py`

- [ ] Task 6: Implement Redis caching layer (AC: 7)
  - [ ] Configure Redis connection in `/apps/api/src/core/cache.py`
  - [ ] Implement cache service in `/apps/api/src/services/cache_service.py`
  - [ ] Add cache warming for frequently used codes
  - [ ] Implement cache invalidation on updates
  - [ ] Add TTL configuration (default 1 hour)

- [ ] Task 7: Create API endpoints (AC: 8)
  - [ ] Add endpoints in `/apps/api/src/api/v1/hs_codes.py`
  - [ ] `GET /api/v1/hs-codes/search` - Vector similarity search
  - [ ] `GET /api/v1/hs-codes/{code}` - Get specific HS code
  - [ ] `GET /api/v1/hs-codes` - List with pagination
  - [ ] `POST /api/v1/hs-codes/bulk` - Bulk import (admin only)
  - [ ] `GET /api/v1/hs-codes/stats` - Usage statistics
  - [ ] Add proper authentication and authorization

- [ ] Task 8: Implement comprehensive testing (All ACs)
  - [ ] Unit tests for HS code repository and services
  - [ ] Integration tests for vector search functionality
  - [ ] Performance tests for query optimization
  - [ ] API endpoint tests with various scenarios
  - [ ] Load tests for bulk operations

## Dev Notes

### Previous Story Insights
[Source: Story 2.1 - File Upload/Validation]
- FastAPI endpoints are established at `/api/v1/` with proper authentication
- Pydantic schemas are used for data validation in `/apps/api/src/schemas/`
- Service layer pattern is established in `/apps/api/src/services/`
- Database models use SQLAlchemy in `/apps/api/src/models/`
- Redis is configured and available for caching
- Testing patterns established with pytest for backend

### Data Models for HS Codes
[Source: architecture/data-models.md#HSCode]

**HSCode Model:**
```typescript
interface HSCode {
  code: string;              // Primary key, e.g., "8471.30"
  description: string;        // Official HS code description
  chapter: string;           // 2-digit chapter code
  section: string;           // Section classification
  embedding: number[];       // OpenAI vector embedding (1536 dimensions)
  country: string;          // Country code (ISO 3166-1 alpha-3)
  isActive: boolean;        // Current validity status
  updatedAt: Date;          // Last update timestamp
}
```

**Relationships:**
- One-to-many with ProductMatch (via matchedHSCode field)

### Database Schema
[Source: architecture/database-schema.md]

**HS Codes Table with pgvector:**
```sql
CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE hs_codes (
    code VARCHAR(10) PRIMARY KEY,
    description TEXT NOT NULL,
    chapter VARCHAR(2) NOT NULL,
    section VARCHAR(2) NOT NULL,
    embedding vector(1536), -- OpenAI embedding size
    country VARCHAR(3) NOT NULL,
    is_active BOOLEAN NOT NULL DEFAULT TRUE,
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Vector similarity search indexes (HNSW for performance)
CREATE INDEX ON hs_codes USING hnsw (embedding vector_cosine_ops);
CREATE INDEX ON hs_codes USING hnsw (embedding vector_l2_ops);
CREATE INDEX idx_hs_codes_country_active ON hs_codes(country, is_active) WHERE is_active = true;
```

### Technology Stack
[Source: architecture/tech-stack.md]

**AI/ML Stack:**
- **OpenAI Agents SDK** (Latest): Production-ready AI agent orchestration
- **OpenAI Vector Store**: Managed vector storage for HS code embeddings
- **pgvector**: PostgreSQL extension for local vector similarity search
- **PostgreSQL 15+**: Primary database with vector search capabilities
- **Redis 7.2+**: Caching layer for frequently accessed HS codes
- **Pydantic 2.5+**: Data validation for HS code schemas

### External API Integration
[Source: architecture/external-apis.md#OpenAI-Agents-SDK-API]

**OpenAI Integration:**
- Uses OpenAI Agents SDK for embedding generation
- FileSearchTool provides direct vector store access
- Built-in retry logic and error handling
- Rate limits: Tier 3 - 5,000 RPM, 160,000 TPM
- Authentication via Bearer token (OpenAI API key)

### File Locations
[Source: architecture/source-tree.md]

**Backend File Structure:**
- `/apps/api/src/models/hs_code.py` - HSCode database model
- `/apps/api/src/repositories/hs_code_repository.py` - Data access layer
- `/apps/api/src/services/embedding_service.py` - OpenAI embedding generation
- `/apps/api/src/services/hs_search_service.py` - Vector similarity search
- `/apps/api/src/services/hs_ingestion_service.py` - Data import/update
- `/apps/api/src/services/cache_service.py` - Redis caching service
- `/apps/api/src/api/v1/hs_codes.py` - API endpoints
- `/apps/api/src/schemas/hs_code.py` - Pydantic validation schemas
- `/apps/api/src/core/cache.py` - Redis configuration
- `/apps/api/alembic/versions/` - Database migrations
- `/scripts/seed-hs-codes.py` - Initial data seeding script

### Coding Standards
[Source: architecture/coding-standards.md]
- **Type Sharing**: Define HSCode types in `/packages/shared/src/types/hs_code.ts`
- **API Routes**: Use kebab-case for endpoints (e.g., `/api/v1/hs-codes`)
- **Database Tables**: Use snake_case (e.g., `hs_codes`)
- **Error Handling**: All API routes must use standard error handler
- **Database Transactions**: Use transactions for bulk operations
- **Environment Variables**: Access through config objects only

### Performance Requirements
- Vector similarity search must return results in <100ms
- Bulk import should handle 5,000+ records efficiently
- Cache hit ratio target: >80% for frequently used codes
- Database indexes optimized for both exact and similarity searches
- Connection pooling configured for concurrent requests

### Security Considerations
- Admin-only access for bulk import operations
- Rate limiting on search endpoints to prevent abuse
- Input validation on all HS code data
- Secure storage of OpenAI API credentials
- Audit logging for data modifications

### Project Structure Alignment
All file locations align with the defined project structure in source-tree.md:
- Models in `/apps/api/src/models/`
- Services in `/apps/api/src/services/`
- API routes in `/apps/api/src/api/v1/`
- Repositories in `/apps/api/src/repositories/`
- Schemas in `/apps/api/src/schemas/`

## Testing

### Testing Standards from Architecture
[Source: architecture/testing-strategy.md]

**Test File Locations:**
- Backend unit tests: `/apps/api/tests/unit/services/test_hs_*.py`
- Backend integration tests: `/apps/api/tests/integration/test_hs_code_integration.py`
- API tests: `/apps/api/tests/integration/api/test_hs_codes_api.py`
- Performance tests: `/apps/api/tests/performance/test_vector_search.py`
- Test fixtures: `/apps/api/tests/fixtures/hs_codes.py`

**Testing Frameworks:**
- Backend: pytest 7+ with httpx 0.25+ for async API testing
- Performance: locust for load testing bulk operations
- Database: pytest-postgresql for isolated database testing

**Testing Requirements for This Story:**
- Unit tests for HSCode model and repository methods
- Unit tests for embedding service with mocked OpenAI calls
- Unit tests for search service with various similarity thresholds
- Integration tests for complete search workflow
- API tests for all endpoints with authentication
- Performance tests validating <100ms query times
- Load tests for bulk import operations (5,000+ records)
- Cache tests for Redis integration and invalidation

**Test Data Requirements:**
- Sample HS codes with varied descriptions
- Pre-generated embeddings for testing
- Country-specific code variations
- Edge cases (special characters, long descriptions)
- Performance test dataset (5,000+ codes)

**Testing Patterns:**
- Mock OpenAI API calls in unit tests
- Use test database with pgvector for integration tests
- Mock Redis for cache testing
- Test transaction rollback in bulk operations
- Validate vector similarity with known matches
- Achieve minimum 90% test coverage

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-08-21 | 1.0 | Initial story creation for HS Code Database Integration | Bob (Scrum Master) |

## Dev Agent Record

**Agent Model Used:** [To be filled by Dev Agent]

### Debug Log References
[To be filled during development]

### Completion Notes
[To be filled during development]

### File List
[To be filled during development]

## QA Results
[To be filled by QA Agent]